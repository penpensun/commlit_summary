{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dca6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "pdf_test = pd.read_csv('./input/prompts_train.csv')\n",
    "sdf_test = pd.read_csv('./input/summaries_train.csv')\n",
    "df_test = pdf_test.merge(sdf_test, on ='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17009571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "\n",
       "                                                text   content   wording  \n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d393d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff37545b2805</td>\n",
       "      <td>In paragraph two, they would use pickle meat a...</td>\n",
       "      <td>1.520355</td>\n",
       "      <td>-0.292990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff4ed38ef099</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff53b94f7ce0</td>\n",
       "      <td>They would have piles of filthy meat on the fl...</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>-1.053294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                    prompt_question  \\\n",
       "0       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "2       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "3       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "4       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "...        ...                                                ...   \n",
       "7160    ebad26  Summarize the various ways the factory would u...   \n",
       "7161    ebad26  Summarize the various ways the factory would u...   \n",
       "7162    ebad26  Summarize the various ways the factory would u...   \n",
       "7163    ebad26  Summarize the various ways the factory would u...   \n",
       "7164    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "0                  On Tragedy   \n",
       "1                  On Tragedy   \n",
       "2                  On Tragedy   \n",
       "3                  On Tragedy   \n",
       "4                  On Tragedy   \n",
       "...                       ...   \n",
       "7160  Excerpt from The Jungle   \n",
       "7161  Excerpt from The Jungle   \n",
       "7162  Excerpt from The Jungle   \n",
       "7163  Excerpt from The Jungle   \n",
       "7164  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text    student_id  \\\n",
       "0     Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1     Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2     Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "3     Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n",
       "4     Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n",
       "...                                                 ...           ...   \n",
       "7160  With one member trimming beef in a cannery, an...  ff37545b2805   \n",
       "7161  With one member trimming beef in a cannery, an...  ff4ed38ef099   \n",
       "7162  With one member trimming beef in a cannery, an...  ff53b94f7ce0   \n",
       "7163  With one member trimming beef in a cannery, an...  ff7c7e70df07   \n",
       "7164  With one member trimming beef in a cannery, an...  fffbccfd8a08   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1     The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2     Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n",
       "3     One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n",
       "4     The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  In paragraph two, they would use pickle meat a...  1.520355 -0.292990  \n",
       "7161  in the first paragraph  it says \"either can it... -1.204574 -1.169784  \n",
       "7162  They would have piles of filthy meat on the fl...  0.328739 -1.053294  \n",
       "7163  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8737b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    set_seed,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset, disable_progress_bar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['WANDB_PROJECT'] = 'kaggle-commonlit-eval-student-summaries'\n",
    "\n",
    "disable_progress_bar()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=\"microsoft/deberta-v3-base\",\n",
    "        metadata={\"help\": \"Model name or path\"},\n",
    "    )\n",
    "\n",
    "    data_dir: Optional[str] = field(\n",
    "        default=\"/kaggle/input/commonlit-evaluate-student-summaries\",\n",
    "        metadata={\"help\": \"Data directory\"},\n",
    "    )\n",
    "\n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=1600,\n",
    "        metadata={\"help\": \"Max sequence length\"},\n",
    "    )\n",
    "\n",
    "    add_prompt_question: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add prompt question into input\"},\n",
    "    )\n",
    "\n",
    "    add_prompt_text: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add prompt text into input\"},\n",
    "    )\n",
    "\n",
    "    fold: Optional[int] = field(\n",
    "        default=0,\n",
    "        metadata={\"help\": \"Fold\"},\n",
    "    )\n",
    "\n",
    "    num_proc: Optional[int] = field(\n",
    "        default=4,\n",
    "        metadata={\"help\": \"Number of processes\"},\n",
    "    )\n",
    "\n",
    "    dropout: Optional[float] = field(\n",
    "        default=0.,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    )\n",
    "    max_position_embeddings: Optional[int] = field(\n",
    "        default=1600,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    )\n",
    "\n",
    "\n",
    "def tokenize(example, tokenizer, config):\n",
    "    sep = tokenizer.sep_token\n",
    "\n",
    "    # if config.add_prompt_question:\n",
    "    #     text = sep.join(\n",
    "    #         [example[\"prompt_question\"], example[\"prompt_text\"], example[\"text\"]]\n",
    "    #     )\n",
    "    # elif config.add_prompt_text:\n",
    "    #     text = sep.join([example[\"prompt_text\"], example[\"text\"]])\n",
    "    # else:\n",
    "    #     text = example[\"text\"]\n",
    "    prompt = sep.join([example[\"prompt_title\"], example[\"prompt_text\"], example[\"prompt_question\"]])\n",
    "    labels = [example[\"content\"], example[\"wording\"]]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        example[\"text\"],\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        max_length=config.max_seq_length,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "def tokenize_inf(example, tokenizer, config):\n",
    "    sep = tokenizer.sep_token;\n",
    "    prompt = sep.join([example[\"prompt_title\"], example[\"prompt_text\"], example[\"prompt_question\"]])\n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        example[\"text\"],\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        max_length=config.max_seq_length,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **tokenized\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8150bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = './output_fold3_seed42_2108'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model_config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "\n",
    "model_config.update({\n",
    "    \"hidden_dropout_prob\": 0,\n",
    "    \"attention_probs_dropout_prob\": 0,\n",
    "    \"num_labels\": 2,\n",
    "    \"problem_type\": \"regression\",\n",
    "    \"max_position_embeddings\":1600,\n",
    "})\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    pad_to_multiple_of=16,\n",
    ")\n",
    "# Do not use pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path, config=model_config\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bd11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4095cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df;\n",
    "        self.tokenizer = tokenizer;\n",
    "        self.max_len = config.max_seq_length;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_row = self.df.iloc[index, :]\n",
    "        #print(data_row)\n",
    "        text_input = self.tokenizer.sep_token.join([data_row[\"prompt_title\"], data_row[\"prompt_text\"], data_row[\"prompt_question\"]])\n",
    "        text_input_paired = data_row['text']\n",
    "        inputs = self.tokenizer(\n",
    "            text_input_paired,\n",
    "            text_input,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            max_length=self.max_len,\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype = torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype = torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265d5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "@torch.no_grad()\n",
    "\n",
    "def test_run(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for idx, data in tqdm(enumerate(loader), total = len(loader)):\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long);\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long);\n",
    "        y_preds = model(ids, mask);\n",
    "        preds.append(y_preds[0].to('cpu').numpy());\n",
    "        del ids, mask\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = np.concatenate(preds)\n",
    "    \n",
    "    return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef9142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3583/3583 [16:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.12350778, -0.23918925],\n",
       "       [-0.9611728 , -1.0675625 ],\n",
       "       [ 0.14993002, -0.7006547 ],\n",
       "       ...,\n",
       "       [ 0.5615608 , -0.11869518],\n",
       "       [-0.17722498, -0.08349483],\n",
       "       [ 0.8947087 ,  0.68251175]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = test_run(model, test_loader)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4b4698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12350778, -0.23918925],\n",
       "       [-0.9611728 , -1.0675625 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74538329",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset.from_pandas(df_test)\n",
    "tokenized_test_ds = test_ds.map(tokenize_inf, batched=False, num_proc=4, fn_kwargs={\"tokenizer\": tokenizer, \"config\": config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06634ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "test_args = TrainingArguments(\n",
    "    output_dir = './',\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = 1,   \n",
    "    dataloader_drop_last = False,\n",
    "    eval_accumulation_steps=1,\n",
    ")\n",
    "\n",
    "# init trainer\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    args = test_args,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "test_results = trainer.predict(tokenized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb3ea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.33315864, -0.40877536],\n",
       "       [-0.34470144, -0.41816443],\n",
       "       [-0.32910156, -0.41634947],\n",
       "       [-0.34233406, -0.42136148]], dtype=float32), label_ids=None, metrics={'test_runtime': 0.2444, 'test_samples_per_second': 16.363, 'test_steps_per_second': 16.363})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2cdc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['student_id'] = df_test['student_id']\n",
    "submission_df['content'] = test_results[0][:, 0]\n",
    "submission_df['wording'] = test_results[0][:, 1]\n",
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfdda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
